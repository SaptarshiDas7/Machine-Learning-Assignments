{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLlu0CJ5jbEI",
        "outputId": "852babdc-ffd8-47a5-a788-7a05463dc5f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMBOVKos6MmJ"
      },
      "source": [
        "# Import necessary packages\n",
        "import argparse\n",
        "\n",
        "# Import necessary components to build LeNet\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import skimage.transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNvs7q8a6RxC"
      },
      "source": [
        "def alexnet_model(img_shape=(224, 224, 3), n_classes=10, l2_reg=0.,\n",
        "\tweights=None):\n",
        "\n",
        "\t# Initialize model\n",
        "\talexnet = Sequential()\n",
        "\n",
        "\t# Layer 1\n",
        "\talexnet.add(Conv2D(30, (11, 11), input_shape=img_shape,\n",
        "\t\tpadding='same', kernel_regularizer=l2(l2_reg)))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 2\n",
        "\talexnet.add(Conv2D(30, (5, 5), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 3\n",
        "\talexnet.add(ZeroPadding2D((1, 1)))\n",
        "\talexnet.add(Conv2D(30, (3, 3), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 4\n",
        "\talexnet.add(ZeroPadding2D((1, 1)))\n",
        "\talexnet.add(Conv2D(30, (3, 3), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\n",
        "\t# Layer 5\n",
        "\talexnet.add(ZeroPadding2D((1, 1)))\n",
        "\talexnet.add(Conv2D(30, (3, 3), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 6\n",
        "\talexnet.add(Flatten())\n",
        "\talexnet.add(Dense(30))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 7\n",
        "\talexnet.add(Dense(30))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 8\n",
        "\talexnet.add(Dense(n_classes))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('softmax'))\n",
        "\n",
        "\tif weights is not None:\n",
        "\t\talexnet.load_weights(weights)\n",
        "\n",
        "\treturn alexnet\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"\n",
        "\tParse command line arguments.\n",
        "\tParameters:\n",
        "\t\tNone\n",
        "\tReturns:\n",
        "\t\tparser arguments\n",
        "\t\"\"\"\n",
        "\tparser = argparse.ArgumentParser(description='AlexNet model')\n",
        "\toptional = parser._action_groups.pop()\n",
        "\trequired = parser.add_argument_group('required arguments')\n",
        "\toptional.add_argument('--print_model',\n",
        "\t\tdest='print_model',\n",
        "\t\thelp='Print AlexNet model',\n",
        "\t\taction='store_true')\n",
        "\tparser._action_groups.append(optional)\n",
        "\treturn parser.parse_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-I9hTl87Z6E"
      },
      "source": [
        "def load_preprocess_training_batch(X_train):\n",
        "    \n",
        "    new = []\n",
        "    \n",
        "    for item in X_train:\n",
        "        tmpFeature = skimage.transform.resize(item, (224, 224), mode='constant')\n",
        "        new.append(tmpFeature)\n",
        "\n",
        "    return new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2TmDo7kUmnS"
      },
      "source": [
        "# CIFAR 10 DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMAVVkm7L6y"
      },
      "source": [
        "# Command line parameters\n",
        "# args = parse_args()\n",
        "\n",
        "# Create AlexNet model\n",
        "model = alexnet_model()\n",
        "\n",
        "# Print\n",
        "# if args.print_model:\n",
        "# \tmodel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ2uuURi86GQ"
      },
      "source": [
        "(X_train, y_train) , (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train = X_train[0:500]\n",
        "y_train = y_train[0:500]\n",
        "X_test = X_test[0:200]\n",
        "y_test = y_test[0:200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7JZqOmw9DYn"
      },
      "source": [
        "X_train_resized = load_preprocess_training_batch(X_train)\n",
        "X_test_resized = load_preprocess_training_batch(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xHCuhNv9O-I"
      },
      "source": [
        "X_train_resized = np.array(X_train_resized)\n",
        "X_test_resized = np.array(X_test_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMpBtT5t9WQ_"
      },
      "source": [
        "X_train_resized = X_train_resized / 255\n",
        "X_test_resized = X_test_resized / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0QYAVF_9YDG",
        "outputId": "c9420444-9ad5-4273-e592-0474825beb36"
      },
      "source": [
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_resized, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "16/16 [==============================] - 61s 4s/step - loss: 2.6788 - accuracy: 0.1240\n",
            "Epoch 2/5\n",
            "16/16 [==============================] - 59s 4s/step - loss: 2.6332 - accuracy: 0.0960\n",
            "Epoch 3/5\n",
            "16/16 [==============================] - 60s 4s/step - loss: 2.5360 - accuracy: 0.1220\n",
            "Epoch 4/5\n",
            "16/16 [==============================] - 59s 4s/step - loss: 2.4222 - accuracy: 0.1400\n",
            "Epoch 5/5\n",
            "16/16 [==============================] - 60s 4s/step - loss: 2.3684 - accuracy: 0.1400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko1in3vw9hXz",
        "outputId": "83221020-a68a-4101-827f-27611bd8bded"
      },
      "source": [
        "model.evaluate(X_test_resized, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 6s 753ms/step - loss: 2.3611 - accuracy: 0.0750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3610661029815674, 0.07500000298023224]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4cxjULYUxwv"
      },
      "source": [
        "# NMIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj_OBI3hU69G"
      },
      "source": [
        "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "X_train = X_train[0:2000]\n",
        "y_train = y_train[0:2000]\n",
        "X_test = X_test[0:2000]\n",
        "y_test = y_test[0:2000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB7e7K7lVsfX"
      },
      "source": [
        "X_train_resized = load_preprocess_training_batch(X_train)\n",
        "X_test_resized = load_preprocess_training_batch(X_test)\n",
        "\n",
        "X_train_resized = np.array(X_train_resized)\n",
        "X_test_resized = np.array(X_test_resized)\n",
        "\n",
        "X_train_resized = X_train_resized / 255.0\n",
        "X_test_resized = X_test_resized / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_iuex7NWaxH"
      },
      "source": [
        "import cv2\n",
        "\n",
        "X_train_new = list()\n",
        "\n",
        "for i in range(len(X_train_resized)):\n",
        "  g  = X_train_resized[i]\n",
        "  X_train_new.append(cv2.merge([g,g,g]))\n",
        "\n",
        "X_train_new = np.asarray(X_train_new,dtype=np.float32)\n",
        "\n",
        "X_test_new = list()\n",
        "\n",
        "for i in range(len(X_test_resized)):\n",
        "  g  = X_test_resized[i]\n",
        "  X_test_new.append(cv2.merge([g,g,g]))\n",
        "\n",
        "X_test_new = np.asarray(X_test_new,dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT3uaXDxWkZH",
        "outputId": "8eef741f-dde1-4424-cb19-ef7219a7c525"
      },
      "source": [
        "model = alexnet_model()\n",
        "\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_new, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "63/63 [==============================] - 474s 8s/step - loss: 2.0734 - accuracy: 0.2610\n",
            "Epoch 2/5\n",
            "63/63 [==============================] - 476s 8s/step - loss: 1.7821 - accuracy: 0.3680\n",
            "Epoch 3/5\n",
            "63/63 [==============================] - 468s 7s/step - loss: 1.6773 - accuracy: 0.4395\n",
            "Epoch 4/5\n",
            "63/63 [==============================] - 469s 7s/step - loss: 1.5820 - accuracy: 0.4810\n",
            "Epoch 5/5\n",
            "63/63 [==============================] - 472s 7s/step - loss: 1.5318 - accuracy: 0.5040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRj8O1-0W-Vv",
        "outputId": "17b31b56-4c17-472f-ee1a-4e1723dff461"
      },
      "source": [
        "model.evaluate(X_test_new, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 107s 2s/step - loss: 2.3417 - accuracy: 0.1170\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3417277336120605, 0.11699999868869781]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MafQRAVJXLJP"
      },
      "source": [
        "# SAVEE Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHrR_A7RXAWf"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/SaveeDataset.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDvIwGlLXRqm"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "input_length = 16000*5\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "n_mels = 320\n",
        "\n",
        "def preprocess_audio_mel_T(audio, sample_rate=16000, window_size=20, #log_specgram\n",
        "                 step_size=10, eps=1e-10):\n",
        "\n",
        "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels= n_mels)\n",
        "    mel_db = (librosa.power_to_db(mel_spec, ref=np.max) + 40)/40\n",
        "\n",
        "    return mel_db.T\n",
        "\n",
        "\n",
        "def load_audio_file(file_path, input_length=input_length):\n",
        "  data = librosa.core.load(file_path, sr=16000)[0] #, sr=16000\n",
        "  if len(data)>input_length:\n",
        "    max_offset = len(data)-input_length\n",
        "    \n",
        "    offset = np.random.randint(max_offset)\n",
        "    \n",
        "    data = data[offset:(input_length+offset)]\n",
        "            \n",
        "  else:\n",
        "    if input_length > len(data):\n",
        "      max_offset = input_length - len(data)\n",
        "\n",
        "      offset = np.random.randint(max_offset)\n",
        "    else:\n",
        "      offset = 0\n",
        "    data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
        "    \n",
        "  data = preprocess_audio_mel_T(data)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0RenEOFXTuf"
      },
      "source": [
        "# Preprocessing the dataset\n",
        "import os\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "rootDirectory = \"/content/AudioData/\"\n",
        "personNames = [\"DC\",\"JE\",\"JK\",\"KL\"]\n",
        "\n",
        "classes = [\"a\" , \"d\" , \"f\", \"h\", \"n\", \"sa\" , \"su\" ]\n",
        "\n",
        "X = list()\n",
        "y = list()\n",
        "\n",
        "for person in personNames:\n",
        "  directory = os.path.join(rootDirectory,person)\n",
        "  for filename in os.listdir(directory):\n",
        "    filePath = os.path.join(directory, filename)\n",
        "    a = load_audio_file(file_path=filePath)\n",
        "    data = cv2.merge([a,a,a])\n",
        "    if(filename[0:1] in classes):\n",
        "      X.append(data)\n",
        "      y.append(classes.index(filename[0:1]))\n",
        "    elif(filename[0:2] in classes):\n",
        "      X.append(data)\n",
        "      y.append(classes.index(filename[0:2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTiaY5ufXXB2"
      },
      "source": [
        "X = np.asarray(X, dtype=np.float32)\n",
        "y = np.asarray(y, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMNhx4VjXYlm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# dataset preparation\n",
        "\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, train_size= 0.5 ,random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpdgRy4yXaQ3"
      },
      "source": [
        "X_train_resized = load_preprocess_training_batch(X_train)\n",
        "X_test_resized = load_preprocess_training_batch(X_test)\n",
        "\n",
        "X_train_resized = np.array(X_train_resized)\n",
        "X_test_resized = np.array(X_test_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABaDUn1pXgjH",
        "outputId": "a2d37b52-c318-4af4-b330-adad18396483"
      },
      "source": [
        "model = alexnet_model()\n",
        "\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_resized, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 99s 7s/step - loss: 2.6041 - accuracy: 0.1167\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 56s 7s/step - loss: 2.5481 - accuracy: 0.1167\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 57s 7s/step - loss: 2.4258 - accuracy: 0.1958\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 56s 7s/step - loss: 2.4215 - accuracy: 0.1583\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 56s 7s/step - loss: 2.2042 - accuracy: 0.2333\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 57s 7s/step - loss: 2.2080 - accuracy: 0.2042\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 56s 7s/step - loss: 2.1114 - accuracy: 0.2792\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 57s 7s/step - loss: 2.1120 - accuracy: 0.2542\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 56s 7s/step - loss: 2.0292 - accuracy: 0.2583\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 57s 7s/step - loss: 2.1150 - accuracy: 0.2417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHaUnU32Xg--",
        "outputId": "5d4c0fbc-0a19-4120-9af7-20e90f7785cd"
      },
      "source": [
        "model.evaluate(X_test_resized, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 13s 2s/step - loss: 2.2758 - accuracy: 0.2375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.275780200958252, 0.23749999701976776]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IjKlohiZSjn"
      },
      "source": [
        "# EmoDB Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_aNb0QAn3Y-"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/EmoDB.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBcBA361n8qd"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "input_length = 16000*5\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "n_mels = 320\n",
        "\n",
        "def preprocess_audio_mel_T(audio, sample_rate=16000, window_size=20, #log_specgram\n",
        "                 step_size=10, eps=1e-10):\n",
        "\n",
        "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels= n_mels)\n",
        "    mel_db = (librosa.power_to_db(mel_spec, ref=np.max) + 40)/40\n",
        "\n",
        "    return mel_db.T\n",
        "\n",
        "\n",
        "def load_audio_file(file_path, input_length=input_length):\n",
        "  data = librosa.core.load(file_path, sr=16000)[0] #, sr=16000\n",
        "  if len(data)>input_length:\n",
        "    max_offset = len(data)-input_length\n",
        "    \n",
        "    offset = np.random.randint(max_offset)\n",
        "    \n",
        "    data = data[offset:(input_length+offset)]\n",
        "            \n",
        "  else:\n",
        "    if input_length > len(data):\n",
        "      max_offset = input_length - len(data)\n",
        "\n",
        "      offset = np.random.randint(max_offset)\n",
        "    else:\n",
        "      offset = 0\n",
        "    data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
        "    \n",
        "  data = preprocess_audio_mel_T(data)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xC7x1Eun-nV"
      },
      "source": [
        "# Preprocessing the dataset\n",
        "import os\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "directory = \"/content/wav/\"\n",
        "\n",
        "classes = [\"W\" ,\"L\" ,\"E\" ,\"A\" , \"F\" ,\"T\" ,\"N\" ]\n",
        "\n",
        "X = list()\n",
        "y = list()\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  filePath = os.path.join(directory, filename)\n",
        "  a = load_audio_file(file_path=filePath)\n",
        "  data = cv2.merge([a,a,a])\n",
        "  if(filename[5:6] in classes):\n",
        "    X.append(data)\n",
        "    y.append(classes.index(filename[5:6]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQBMSTM3sS-O"
      },
      "source": [
        "X = np.asarray(X, dtype=np.float32)\n",
        "y = np.asarray(y, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CCtN-veoArO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# dataset preparation\n",
        "\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, train_size= 0.6 ,random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLjmziVOoFbl"
      },
      "source": [
        "X_train_resized = load_preprocess_training_batch(X_train)\n",
        "X_test_resized = load_preprocess_training_batch(X_test)\n",
        "\n",
        "X_train_resized = np.array(X_train_resized)\n",
        "X_test_resized = np.array(X_test_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FlxLoSooX-G",
        "outputId": "a24d1915-4a1e-47a6-f67a-cfe6f7ed37e1"
      },
      "source": [
        "model = alexnet_model()\n",
        "\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_resized, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 78s 7s/step - loss: 2.6594 - accuracy: 0.0997\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 75s 7s/step - loss: 2.4658 - accuracy: 0.1121\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 75s 7s/step - loss: 2.4722 - accuracy: 0.1402\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 75s 7s/step - loss: 2.3171 - accuracy: 0.1776\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 75s 7s/step - loss: 2.2610 - accuracy: 0.1838\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 75s 7s/step - loss: 2.1741 - accuracy: 0.2025\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 77s 7s/step - loss: 2.0738 - accuracy: 0.2336\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 76s 7s/step - loss: 2.0492 - accuracy: 0.2679\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 76s 7s/step - loss: 2.0359 - accuracy: 0.2679\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 76s 7s/step - loss: 1.9726 - accuracy: 0.3115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VVU2ox_ocMn",
        "outputId": "fdb636e8-debb-47b3-91c8-ccc638bc9231"
      },
      "source": [
        "model.evaluate(X_test_resized, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 12s 2s/step - loss: 2.1748 - accuracy: 0.2336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.1748006343841553, 0.23364485800266266]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}